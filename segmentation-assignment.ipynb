{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851d1c2-cc72-43e8-a43f-990f488d64af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "580d00fdc1d82bcf3e8e83191e4dc15f",
     "grade": false,
     "grade_id": "cell-000ed7fdeb60da94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513acc0-09dc-40fa-a77d-b1e2ce2f4526",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f225f521d2dcea1f45462dd37147b95",
     "grade": false,
     "grade_id": "cell-fc931a8b1c342aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(\"Using Colab:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74383426-f224-4bf8-a10e-177c62fe75c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4db6890b865cc1ca57d7a61ae550ba16",
     "grade": false,
     "grade_id": "cell-799cc8fb877a9d73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Segmentation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72e8d3-3b56-4fca-b817-6703b77fd499",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbac37459894409330123fbf2f4e94ca",
     "grade": false,
     "grade_id": "cell-78781dae47226dbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## TODO 0: Dataset Download\n",
    "\n",
    "- Download the CCP dataset from https://www.kaggle.com/datasets/balraj98/clothing-coparsing-dataset and save it to drive.\n",
    "- You can use:\n",
    "```bash\n",
    "curl -L -o /content/drive/My\\ Drive/clothing-coparsing-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/balraj98/clothing-coparsing-dataset\n",
    "```\n",
    "- Then, update this `datasetroot` link to point to the dataset.\n",
    "- Update `projectroot` to point to where you want to store your outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d69104-4014-4757-bc7e-a4cbc93a7a24",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f16eb9e91111b8160ea30c195dbb513",
     "grade": false,
     "grade_id": "cell-6b95b4ae8f93bb0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    datasetroot = '/content/drive/My Drive/ccp/' # edit this \n",
    "    projectroot = '/content/drive/My Drive/ccp_root/' # edit this\n",
    "else:\n",
    "    datasetroot = \"../../../clothing-coparsing-dataset/\" # edit this\n",
    "    projectroot = \"./test_outputs\" # edit this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac36611-3a8a-4933-b60c-fbe929960f6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "797f169f67ca4e778499e85d8850446c",
     "grade": false,
     "grade_id": "cell-89ac24e6a2a362b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_rgb_to_labels(mask_rgb: torch.Tensor, df: pd.DataFrame, ignore_index: int = -1):\n",
    "    \"\"\"\n",
    "    Convert an RGB segmentation mask tensor to:\n",
    "    (1) class index tensor, and\n",
    "    (2) one-hot encoded tensor.\n",
    "\n",
    "    mask_rgb: torch.Tensor, shape (H, W, 3) or (3, H, W)\n",
    "    df: pandas dataframe with columns ['r', 'g', 'b']\n",
    "    ignore_index: index to assign to unknown colors\n",
    "\n",
    "    Returns:\n",
    "        index_tensor: (H, W) long tensor\n",
    "        one_hot_tensor: (num_classes, H, W) float tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Normalize mask shape to (H, W, 3) ---\n",
    "    if mask_rgb.shape[0] == 3:  # (3, H, W) → (H, W, 3)\n",
    "        mask_rgb = mask_rgb.permute(1, 2, 0)\n",
    "    mask_rgb = mask_rgb.long()\n",
    "\n",
    "    H, W, _ = mask_rgb.shape\n",
    "\n",
    "    # --- Build mapping dict: (r,g,b) → index ---\n",
    "    df = df.reset_index(drop=True)\n",
    "    rgb_keys = (df[\"r\"] * 256**2 + df[\"g\"] * 256 + df[\"b\"]).astype(int)\n",
    "    rgb2idx = {int(k): int(i) for i, k in enumerate(rgb_keys)}\n",
    "\n",
    "    # --- Compute key for each pixel ---\n",
    "    keys = (\n",
    "        mask_rgb[..., 0] * 256**2\n",
    "        + mask_rgb[..., 1] * 256\n",
    "        + mask_rgb[..., 2]\n",
    "    )\n",
    "\n",
    "    # --- Convert to indices with lookup ---\n",
    "    # Build lookup table as tensor for speed\n",
    "    # (max RGB key is < 256^3 = 16.7M)\n",
    "    max_key = 256**3\n",
    "    lut = torch.full((max_key,), ignore_index, dtype=torch.long)\n",
    "    for k, idx in rgb2idx.items():\n",
    "        lut[k] = idx\n",
    "\n",
    "    index_tensor = lut[keys]\n",
    "\n",
    "    # --- One-hot encode ---\n",
    "    num_classes = len(df)\n",
    "    one_hot = torch.nn.functional.one_hot(index_tensor.clamp(min=0), num_classes)\n",
    "    one_hot = one_hot.permute(2, 0, 1).float()  # (H,W,C) → (C,H,W)\n",
    "\n",
    "    return index_tensor, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0eba9-3003-4a75-9f91-676add8522b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c20fca9451a8331504f6c1e88207558a",
     "grade": false,
     "grade_id": "cell-104a0d258e908a79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClothesParsingDataset:\n",
    "    def __init__(self, train=True, make_binary=False, bg_label=0):\n",
    "        self.imagefolder = os.path.join(datasetroot,'images')\n",
    "        self.maskfolder = os.path.join(datasetroot, 'labels', 'pixel_level_labels_colored')\n",
    "\n",
    "        self.class_dict = os.path.join(datasetroot, \"class_dict.csv\")\n",
    "        self.class_dict = pd.read_csv(self.class_dict)\n",
    "\n",
    "        # train_set = range(1,1000,2)\n",
    "        # val_set = range(2,1000,2)\n",
    "        train_set = range(1,800)\n",
    "        val_set = range(800, 1000)\n",
    "        \n",
    "        if train:\n",
    "            self.idx = train_set\n",
    "        else:\n",
    "            self.idx = val_set\n",
    "\n",
    "        ### We will resize the images to fixed size.\n",
    "        # self.transform = transforms.Compose([transforms.Resize((384, 256)), transforms.ToTensor()])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((384, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ])\n",
    "        self.masktransform = transforms.Resize((384,256), Image.NEAREST)\n",
    "        self.numclasses = self.class_dict.shape[0]\n",
    "        \n",
    "\n",
    "        self.make_binary = make_binary\n",
    "        if self.make_binary:\n",
    "            self.numclasses = 2\n",
    "        self.bg_label = bg_label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i>=self.__len__():\n",
    "            raise IndexError\n",
    "        i = self.idx[i]\n",
    "        imgpath = os.path.join(self.imagefolder, '{:04d}.jpg'.format(i+1))\n",
    "        maskpath = os.path.join(self.maskfolder, '{:04d}.png'.format(i+1))\n",
    "        img = self.transform(Image.open(imgpath).convert('RGB'))\n",
    "        mask, _ = mask_rgb_to_labels(torch.as_tensor(\n",
    "            np.array(Image.open(maskpath)), dtype=torch.int64\n",
    "        ), self.class_dict)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        mask = self.masktransform(mask)\n",
    "        mask = mask[0,:,:]\n",
    "        if self.make_binary:\n",
    "            mask[mask != self.bg_label] = 1\n",
    "        return img, mask.long()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d72057-8ca2-44c2-bc88-abf1571a21d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99292f4cdf432b0151816fc276a25aef",
     "grade": false,
     "grade_id": "cell-609af2b253c9cb74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Visualize the images and masks\n",
    "traindataset = ClothesParsingDataset(train=True)\n",
    "img, mask = traindataset[0]\n",
    "plt.figure(); plt.imshow(img.numpy().transpose(1,2,0))\n",
    "plt.figure(); plt.imshow(mask.numpy(), cmap='hsv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e7b4f-4708-4891-87f2-6771ecdd91f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34f0ce942fb27df79213180f80e7c2b1",
     "grade": false,
     "grade_id": "cell-2f575b4d5e3491bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## TODO 1: ResNet Segmenter\n",
    "\n",
    "- We will now implement a ResNet-based segmentation module.\n",
    "- The goal is to define a module that, given a layer ID, extracts the feature map from the corresponding layer and then up-samples it to the original image dimension.\n",
    "- Finally, we will run a 1-dimensional convolutional layer on the extracted feature map that outputs a distribution over the clothing classes.\n",
    "\n",
    "1. **TODO 1(a)**: Populate this dictionary that maps ResNet15 blocks to the corresponding channel dimension amd the downsampling factor.\n",
    "    - In the function below, define `resnet_layer_to_dims` and `resnet_layer_to_scale` where the keys are integers (each for layer, starting with 1), and the values are the values of channel dimensions and upsampling factors respectively.\n",
    "    - Hint: Look at the source code for the ResNet15 class in pytorch torchvision, and look at `layer1`, `layer2`, `layer3`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197344eb-60d4-4fd7-bc3b-6fd96f214a37",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5d08030c51ef17f8a1da10ab998970f",
     "grade": false,
     "grade_id": "cell-d28d6de831fc4038",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_layer_configs():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return resnet_layer_to_dims, resnet_layer_to_scale\n",
    "\n",
    "resnet_layer_to_dims, resnet_layer_to_scale = get_layer_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461647c6-ed29-4b4a-a81f-2fc7249d2ddb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1f0c201ac3b9487fa732c1721b68440",
     "grade": true,
     "grade_id": "cell-95ba774b4926c261",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "102fe20d-ca99-49ea-863a-3d71daccd19c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1702f8bad18bbff86f0ebc21b4337185",
     "grade": false,
     "grade_id": "cell-bfddd7f22c09239f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "2. **TODO 1(b)**: Create a CNN that uses featuremaps from the desired layerid of a pretrained ResNet18, and applies a single convolutional layer to produce a set of class scores per pixel. The output should be upsampled back to the size of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105731d6-2608-4388-b422-33a6b28698c4",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "306a1cc82ca0b4882441453d56250cd7",
     "grade": false,
     "grade_id": "cell-76a606ef26858b13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNwithResnetFeatures(nn.Module):\n",
    "    def __init__(self, numclasses, layerid):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b73874-45f0-4df6-8d76-88b655fc8291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f185faa0141332168c8fac9b068198e",
     "grade": true,
     "grade_id": "cell-708979f1ead4013c",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "model = CNNwithResnetFeatures(numclasses=100, layerid=3)\n",
    "assert model(img[None]).shape == (1, 100, 384, 256)\n",
    "model = CNNwithResnetFeatures(numclasses=100, layerid=2)\n",
    "assert model(img[None]).shape == (1, 100, 384, 256)\n",
    "model = CNNwithResnetFeatures(numclasses=100, layerid=1)\n",
    "assert model(img[None]).shape == (1, 100, 384, 256)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515a03b-9921-44a5-aac1-3d6cb87d679d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98b5de8f05042e7aae7bdf64ed74394",
     "grade": false,
     "grade_id": "cell-4f123cd40345aa80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## TODO 2: Make GPUs go brrr... :) \n",
    "\n",
    "Write code to train the model. Use 20 epochs, and Adam as an optimizer with default hyperparameters\n",
    "\n",
    "There are some extra parameters in this function that you can try to use for improving the performance of your model:\n",
    "\n",
    "1. `use_weighted_loss`: Use a class-weighted loss for handling class imbalance\n",
    "2. `class_wts`: Required if `use_weighted_loss==True`. Is a $C$-dimensional tensor where $C$ is the number of classes in your dataset.\n",
    "3. `ignore_index`: See [`nn.CrossEntropyLoss`](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8452df-c9e0-4d23-a81f-9eb152e62031",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e02b358fe5c11230477f10096891f2a",
     "grade": false,
     "grade_id": "cell-d30ca0c4cef5a55a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=20,\n",
    "    lr=1e-6,\n",
    "    weight_decay=0,\n",
    "    save_path='/content/drive/My Drive/ccp_models/',\n",
    "    use_weighted_loss=True,\n",
    "    class_wts=None,\n",
    "    ignore_index=-100,\n",
    "):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1e4f4-2fa5-48e5-98aa-3e9f2f83db9e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dset = ClothesParsingDataset(train=True)\n",
    "val_dset = ClothesParsingDataset(train=False)\n",
    "train_dataloader = DataLoader(train_dset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dset, batch_size=8, shuffle=False)\n",
    "\n",
    "renet_features_3 = CNNwithResnetFeatures(train_dset.numclasses, 3)\n",
    "renet_features_3 = renet_features_3.cuda()\n",
    "outputdir = os.path.join(projectroot, 'checkpoints', \"layer_3\") # Replace with an appropriate path\n",
    "final_model = train(renet_features_3, train_dataloader, val_dataloader, \\\n",
    "                    epochs=10, save_path = outputdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2a781-4d80-4d0f-88d8-cc27c6cc2efe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b61fd8d60946e5250c02834242067260",
     "grade": false,
     "grade_id": "cell-b7cd7aa64c6146b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## TODO 3: Evaluate your model\n",
    "\n",
    "**TODO 3(a)**: Write code to compute per-class accuracy given a vector of predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764403f-08e8-4eb3-9c58-1c9405981113",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dc9e95f8cd6b687dda5c6827b8a2079",
     "grade": false,
     "grade_id": "cell-d54db4b02c71bdfb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_perclass_accuracy(predictions, labels):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c6e9d-dc03-4a4b-80fc-c5cf4c76ebe7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6c38e2af0fb49f3f4c870d48e5dc18",
     "grade": false,
     "grade_id": "cell-3f28ca1f76cb980f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_and_save_vis(model, dset, output_folder):\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    all_predicted = []\n",
    "    all_true = []\n",
    "    for i, (x, y) in enumerate(tqdm(dset)):\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.cuda()\n",
    "        scores = model(x)\n",
    "        shape = scores.shape[2:]\n",
    "        scores = scores.reshape((scores.shape[1], -1))\n",
    "        predicted = torch.argmax(scores, dim=0).cpu().numpy()\n",
    "        all_predicted.append(predicted)\n",
    "        all_true.append(y.numpy().reshape(-1))\n",
    "        predicted_map = predicted.reshape(shape)\n",
    "        predicted_img = Image.fromarray(predicted_map.astype(np.uint8))\n",
    "        predicted_img.save(os.path.join(output_folder, f'{i}.png'))\n",
    "        truey = Image.fromarray(y.numpy().astype(np.uint8))\n",
    "        truey.save(os.path.join(output_folder, f'{i}_gt.png'))\n",
    "    return compute_perclass_accuracy(np.concatenate(all_predicted, axis=0), np.concatenate(all_true, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b412713-bcfd-4f06-b33d-9d73b7f83060",
   "metadata": {},
   "outputs": [],
   "source": [
    "perclass_acc = eval_and_save_vis(\n",
    "    final_model, \n",
    "    ClothesParsingDataset(train=False), os.path.join(projectroot, \"outputs\", \"layer_3\"))\n",
    "print(np.nanmean(perclass_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf1640-8253-4720-b0f1-7e814aefe3e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "219678f59cfa78d1cb48645979679c57",
     "grade": true,
     "grade_id": "cell-dfc819a7fa6404cf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.nanmean(perclass_acc) >= 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be572b-90c8-452b-8e57-a127500ed105",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdataset = ClothesParsingDataset(train=False)\n",
    "img, mask = valdataset[2]\n",
    "predicted = Image.open(os.path.join(projectroot, \"outputs\", \"layer_3\", \"2.png\"))\n",
    "gt = Image.open(os.path.join(projectroot, \"outputs\", \"layer_3\", \"2_gt.png\"))\n",
    "plt.figure(); plt.imshow(predicted)\n",
    "plt.figure(); plt.imshow(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dba7d-fae5-472b-b191-a1ea85cf2ce5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96cb8c0faa187fd4285e98ed7cd2d417",
     "grade": false,
     "grade_id": "cell-958be7ca864ae037",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TODO 3(b)**: Try the same experiment with Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aeeaa2-e952-4a99-9804-15c1635c9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "renet_features_4 = CNNwithResnetFeatures(100, 4)\n",
    "train_dataloader = DataLoader(ClothesParsingDataset(train=True), batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(ClothesParsingDataset(train=False), batch_size=8, shuffle=False)\n",
    "renet_features_4 = renet_features_4.cuda()\n",
    "final_model = train(renet_features_4, train_dataloader, val_dataloader, epochs=10, \n",
    "                    save_path=os.path.join(projectroot, \"checkpoints\", \"layer_4\"))\n",
    "perclass_acc = eval_and_save_vis(final_model, ClothesParsingDataset(train=False), os.path.join(projectroot, \"outputs\", \"layer_4\"))\n",
    "print(np.nanmean(perclass_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f99a22-6351-4bb4-844d-ce6c6661e1aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00cf903e0c051531ba4040d530137605",
     "grade": true,
     "grade_id": "cell-8cc1dc654d333ff0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert np.nanmean(perclass_acc) >= 0.07\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307d404-cc18-48d6-9332-cc17d5077607",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdataset = ClothesParsingDataset(train=False)\n",
    "img, mask = valdataset[2]\n",
    "predicted = Image.open(os.path.join(projectroot, \"outputs\", \"layer_4\", \"1.png\"))\n",
    "gt = Image.open(os.path.join(projectroot, \"outputs\", \"layer_4\", \"1_gt.png\"))\n",
    "plt.figure(); plt.imshow(predicted)\n",
    "plt.figure(); plt.imshow(gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c43f1d-c64d-496b-892d-b8dad2775191",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ef6acf36e99c5ab616b1a37731a2336",
     "grade": false,
     "grade_id": "cell-97154a159707fb88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## TODO 4: This problem needs U(-Net)!\n",
    "\n",
    "In this question, we will build a U-Net architecture.\n",
    "\n",
    "1. Just as you did with ResNet \n",
    "2. Your network should upsample `layer4`, `layer3` and `layer2` to the dimensionality and scale of `layer1` using a `ConvTranspose2d`.\n",
    "3. Then add the upsampled features to `layer1` and add a convolutional layer to produce the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7901761-c5d4-4d3b-8f89-747e045ca05d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b867707999b815abd994dccd87d6b836",
     "grade": false,
     "grade_id": "cell-0c6752d83df41f32",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class UNetwithResnetFeatures(nn.Module):\n",
    "    def __init__(self, numclasses):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533bd6a5-2dbe-4dcb-8522-e8131ba9aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dset = ClothesParsingDataset(train=True)\n",
    "val_dset = ClothesParsingDataset(train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dset, batch_size=32, shuffle=False)\n",
    "my_unet = UNetwithResnetFeatures(train_dset.numclasses)\n",
    "my_unet = my_unet.cuda()\n",
    "final_model = train(my_unet, train_dataloader, val_dataloader, epochs=10, lr=1e-3,\n",
    "                    save_path=os.path.join(projectroot, \"checkpoints\", \"unet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09c980-504a-4c97-9720-a6fedb6b1aae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27d094bc13ab88b241dd285b881b08cb",
     "grade": false,
     "grade_id": "cell-887f28ef8cade51b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "perclass_acc_unet = eval_and_save_vis(final_model, ClothesParsingDataset(train=False), \n",
    "                                 os.path.join(projectroot, \"outputs\", \"unet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470a781-5908-4f08-b484-874806a94c98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c58a4a1f114e3f537d83ea6621d1a1cb",
     "grade": false,
     "grade_id": "cell-034e84c307456919",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "valdataset = ClothesParsingDataset(train=False)\n",
    "img, mask = valdataset[1]\n",
    "predicted = Image.open(os.path.join(projectroot, \"outputs\", \"unet\", \"1.png\"))\n",
    "gt = Image.open(os.path.join(projectroot, \"outputs\", \"unet\", \"1_gt.png\"))\n",
    "plt.figure(); plt.imshow(predicted)\n",
    "plt.figure(); plt.imshow(gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f322a03-213d-4946-a9aa-2ec8ae3ae643",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fa1e4f4b01e94a0e289bf925a411d64",
     "grade": false,
     "grade_id": "cell-7fcc6551a1201a5c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### TODO 4(a): Report the performance of your U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adf8e5-7724-4510-836b-0bd05d7ff870",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "193d4ee495f3cd914b9cf59142b0698a",
     "grade": true,
     "grade_id": "cell-857db86d45739201",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5b409-bf3a-4b83-8c13-1e8b49a799a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1db918dea37482fa2af4f5057a94746",
     "grade": false,
     "grade_id": "cell-eae75fe485a3d4cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### TODO 4(b): Try binary segmentation\n",
    "\n",
    "Take the same U-Net model and try training it for binary segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94b7e1-fb0b-429a-8548-258e63bcf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dset = ClothesParsingDataset(train=True, make_binary=True)\n",
    "val_dset = ClothesParsingDataset(train=False, make_binary=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dset, batch_size=32, shuffle=False)\n",
    "mymodel = UNetwithResnetFeatures(train_dset.numclasses)\n",
    "mymodel = mymodel.cuda()\n",
    "final_model = train(mymodel, train_dataloader, val_dataloader, epochs=10, lr=1e-3,\n",
    "                    save_path=os.path.join(projectroot, \"checkpoints\", \"unet\"), use_weighted_loss=True, class_wts=class_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530a59f-62a1-47ca-8094-fa0ef72c1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perclass_acc_unet = eval_and_save_vis(final_model, ClothesParsingDataset(train=False), \n",
    "                                 os.path.join(projectroot, \"outputs\", \"unet_binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4d186-e43d-4b5d-9921-a94df4c4cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmean(perclass_acc_unet), perclass_acc_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61d2f2-a535-40f5-b8f1-873f71651c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdataset = ClothesParsingDataset(train=False)\n",
    "img, mask = valdataset[1]\n",
    "predicted = Image.open(os.path.join(projectroot, \"outputs\", \"unet_binary\", \"1.png\"))\n",
    "gt = Image.open(os.path.join(projectroot, \"outputs\", \"unet_binary\", \"1_gt.png\"))\n",
    "plt.figure(); plt.imshow(predicted)\n",
    "plt.figure(); plt.imshow(gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17417a06-8515-44de-bc21-eb7a98080422",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ace8ec3f407d41186c045094dfec28f",
     "grade": false,
     "grade_id": "cell-6db03eca0c3dcbf1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### TODO 4(c): Some questions...\n",
    "\n",
    "1. Did you observe a difference in the performance of your model on binary segmentation and multi-class segmentation? If yes, what was it?\n",
    "2. Did you try any approaches to improve the performances of either of your models? If yes, tell us about them!\n",
    "3. Did your model perform equally well on all classes in your multi-class segmentation model?\n",
    "    1. If not, which classes did it perform better than others on? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61953d71-3b3d-4dc8-b0bc-0c02439ee9e8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "560d8d2aa0db82495e0766ba6230f7fc",
     "grade": true,
     "grade_id": "cell-bccd2a36902ea598",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac709fcd-28da-4013-bce0-0ef30502d84f",
   "metadata": {},
   "source": [
    "# What to turn in?\n",
    "\n",
    "Submit a zip file containing the following:\n",
    "\n",
    "1. The final model checkpoints for your binary segmentation and multi-class segmentation model.\n",
    "2. A `.py` file containing the class `UNetwithResnetFeatures` and the function `compute_perclass_accuracy`\n",
    "3. An `.ipynb` file containing the completed notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad444b8-91df-4917-a467-626e9a37101e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5672",
   "language": "python",
   "name": "cs5672"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
